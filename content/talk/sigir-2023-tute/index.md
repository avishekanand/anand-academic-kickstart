---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Tutorial: Explainable Information Retrieval"
event: SIGIR 2023
event_url: "https://sigir.org/sigir2023/"
location: "Taipei(SIGIR)"
address:
  street:
  city:
  region:
  postcode:
  country:
summary: "Explainable Information Retrieval"
abstract: "This tutorial presents explainable information retrieval (ExIR), an emerging area focused on fostering responsible and trustworthy deployment of machine learning systems in the context of information retrieval. As the field has rapidly evolved in the past 4-5 years, numerous approaches have been proposed that focus on different access modes, stakeholders, and model development stages. This tutorial aims to introduce IR-centric notions, classification, and evaluation styles in ExIR, while focusing on IR-specific tasks such as ranking, text classification, and learning-to-rank systems. We will delve into method families and their adaptations to IR, extensively covering post-hoc methods, axiomatic and probing approaches, and recent advances in interpretability-by-design approaches. We will also discuss ExIR applications for different stakeholders, such as researchers, practitioners, and end-users, in contexts like web search, patent and legal search, and high-stakes decision-making tasks. To facilitate practical understanding, we will provide a hands-on session on applying ExIR methods, reducing the entry barrier for students, researchers, and practitioners alike.
"

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: 2023-07-22T9:00:22+02:00
date_end: 2023-07-22T12:30:22+02:00
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: 2020-07-19T14:47:22+02:00

authors: [Avishek Anand]
tags: []

# Is this a featured talk? (true/false)
featured: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

# Optional filename of your slides within your talk's folder or a URL.
url_slides: "https://arxiv.org/pdf/2211.02405.pdf"

url_code:
url_pdf: "https://arxiv.org/pdf/2211.02405.pdf"
url_video: ""

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---
This half-day tutorial is divided into two parts of 90 minutes each -- In the first part we explore the notions of explainable IR, probing neural models and explainable-by-design approaches. In the second half, we delve deeper into axiomatic IR and its connection to interpretability and some of the popular posthoc approaches. 

<br>

## Contents

 1. **[Notions of Explainable IR](https://arxiv.org/pdf/2211.02405.pdf)** by [Avishek Anand](http://www.avishekanand.com). 
 2. **[Intrinsic Methods for ExIR](https://arxiv.org/pdf/2211.02405.pdf)** by [Avishek Anand](http://www.avishekanand.com). 
 3. **[Probing transformer models](https://arxiv.org/pdf/2211.02405.pdf)** by [Avishek Anand](http://www.avishekanand.com). 

<br>    

4. **[Posthoc approaches in ExIR](https://arxiv.org/pdf/2211.02405.pdf)** by [Procheta Sen](https://procheta.github.io/sprocheta/). 
5. **[Axiomatic IR for Interpretability](https://arxiv.org/pdf/2211.02405.pdf)** by [Sourav Saha](https://souravsaha.github.io). 
6. **[Outlook and Conclusion](https://arxiv.org/pdf/2211.02405.pdf)** by [Avishek Anand](https://www.avishekanand.com). 


<br>


---
## References

<br>

[1] Julius Adebayo, Justin Gilmer, Michael Muelly, Ian J. Goodfellow, Moritz Hardt, and Been Kim. 2018. Sanity Checks for Saliency Maps. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada, Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò Cesa-Bianchi, and Roman Garnett (Eds.). 9525–9536. https://proceedings. neurips.cc/paper/2018/hash/294a8ed24b1ad22ec2e7efea049b8737- Abstract.html

